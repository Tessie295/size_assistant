import uuid
from typing import Dict, Any, Optional, List
from data.data_loader import DataLoader
from engine.size_recommendation_engine import SizeRecommendationEngine
from services.llm_service import LLMService
from services.rag_service import RAGService
from services.conversation_manager import ConversationManager
from models.data_models import Client, Product, SizeRecommendation


from services.visual_service import VisualService
VISUAL_AVAILABLE = True

class SizingChatbot:
    """Chatbot para recomendaciones de tallas."""
    
    def __init__(self, data_dir: str = "data"):
        """Inicializa el chatbot con todos sus componentes."""
        # Inicializar componentes b√°sicos
        self.data_loader = DataLoader(data_dir)
        self.recommendation_engine = SizeRecommendationEngine()
        self.llm_service = LLMService()
        self.rag_service = RAGService(self.data_loader)
        self.conversation_manager = ConversationManager()
        
        # Inicializar servicio visual si est√° disponible
        self.visual_service = None
        if VISUAL_AVAILABLE:
            try:
                self.visual_service = VisualService()
                if not self.visual_service.is_available():
                    print("‚ö†Ô∏è Servicio visual: PIL no disponible")
                else:
                    print("‚úÖ Servicio visual: Disponible")
            except Exception as e:
                print(f"‚ö†Ô∏è Error inicializando servicio visual: {e}")
        
        # Estado del chatbot
        self.is_initialized = self._check_initialization()
    
    def _check_initialization(self) -> bool:
        """Verifica que todos los componentes est√©n correctamente inicializados."""
        try:
            if not self.data_loader.is_loaded():
                print("‚ùå Datos no cargados correctamente")
                return False
            
            print(f"‚úÖ Chatbot inicializado correctamente")
            print(f"   - {len(self.data_loader.clients)} clientes")
            print(f"   - {len(self.data_loader.products)} productos") 
            print(f"   - LLM: {'OpenAI' if self.llm_service.use_openai else 'Local'}")
            print(f"   - Visual: {'‚úÖ' if self.visual_service and self.visual_service.is_available() else '‚ùå'}")
            return True
            
        except Exception as e:
            print(f"‚ùå Error en la inicializaci√≥n: {e}")
            return False
    
    def start_conversation(self, session_id: Optional[str] = None) -> str:
        """Inicia una nueva conversaci√≥n."""
        if not session_id:
            session_id = str(uuid.uuid4())
        
        self.conversation_manager.start_session(session_id)
        
        # Mensaje de bienvenida
        welcome_message = (
            "¬°Hola! üëã Soy tu asistente personal de tallas.\n\n"
            "Puedo ayudarte a encontrar la talla perfecta para cualquier prenda."
        )
        
        if self.visual_service and self.visual_service.is_available():
            welcome_message += " Tambi√©n puedo generar visualizaciones de c√≥mo te queda la ropa."
        
        welcome_message += (
            "\n\n**Ejemplos de consultas:**\n"
            "‚Ä¢ \"¬øQu√© talla del producto P001 para el cliente C0001?\"\n"
            "‚Ä¢ \"Busca productos de lana\""
        )
        
        if self.visual_service and self.visual_service.is_available():
            welcome_message += "\n‚Ä¢ \"Muestra P005 en azul para C0002\""
        
        self.conversation_manager.add_turn(
            session_id=session_id,
            user_message="[INICIO_CONVERSACION]",
            assistant_response=welcome_message,
            metadata={"turn_type": "welcome"}
        )
        
        return session_id
    
    def process_message(self, message: str, session_id: str) -> Dict[str, Any]:
        """Procesa un mensaje del usuario y genera una respuesta."""
        if not self.is_initialized:
            return {
                "response": "Lo siento, el sistema no est√° inicializado correctamente. "
                           "Por favor, verifica que los archivos de datos est√©n en la carpeta 'data/'.",
                "error": True
            }
        
        try:
            print(f"\nüîç Procesando: '{message}'")
            
            # 1. Parsear la consulta con RAG
            parsed_query = self.rag_service.parse_query(message)
            print(f"üìã Productos: {parsed_query['product_ids']}, Clientes: {parsed_query['client_ids']}")
            
            # 2. Recuperar contexto relevante
            context = self.rag_service.retrieve_context(parsed_query)
            print(f"üìä Contexto: {len(context['clients'])} clientes, {len(context['products'])} productos")
            
            # 3. Procesar seg√∫n la intenci√≥n
            response_data = self._process_by_intent(message, session_id, parsed_query, context)
            
            # 4. A√±adir contenido visual si se solicita y es posible
            if (parsed_query.get('has_visual_intent', False) and 
                self.visual_service and 
                self.visual_service.is_available() and
                response_data.get('recommendation') and
                response_data.get('client') and
                response_data.get('product')):
                
                print("üñºÔ∏è Generando contenido visual...")
                visual_result = self._generate_visual_content(message, response_data)
                if visual_result and visual_result.get('success'):
                    response_data['visual'] = visual_result
                    response_data['response'] += "\n\nüñºÔ∏è He generado una visualizaci√≥n de c√≥mo te queda la prenda."
                elif visual_result:
                    print(f"‚ö†Ô∏è Error visual: {visual_result.get('error')}")
            
            # 5. A√±adir turno a la conversaci√≥n
            self.conversation_manager.add_turn(
                session_id=session_id,
                user_message=message,
                assistant_response=response_data["response"],
                context=context,
                metadata=response_data.get("metadata", {})
            )
            
            print("‚úÖ Mensaje procesado exitosamente")
            return response_data
            
        except Exception as e:
            print(f"‚ùå Error procesando mensaje: {e}")
            import traceback
            traceback.print_exc()
            
            # Respuesta de fallback
            error_response = (
                "Lo siento, ocurri√≥ un error al procesar tu mensaje. "
                "¬øPodr√≠as intentar reformular tu consulta? Por ejemplo: "
                "'¬øQu√© talla del producto P001 para el cliente C0001?'"
            )
            
            return {
                "response": error_response,
                "error": True,
                "error_details": str(e)
            }
    
    def _process_by_intent(
        self, 
        message: str, 
        session_id: str, 
        parsed_query: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Procesa el mensaje seg√∫n la intenci√≥n identificada."""
        
        intent = context.get('intent', 'general')
        print(f"üéØ Intenci√≥n: {intent}")
        
        if intent == 'size_recommendation':
            return self._handle_size_recommendation(message, session_id, context)
        elif intent == 'product_search':
            return self._handle_product_search(message, session_id, context)
        elif intent == 'help':
            return self._handle_help_request()
        else:
            return self._handle_general_query(message, context)
    
    def _handle_size_recommendation(
        self, 
        message: str, 
        session_id: str, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Maneja solicitudes de recomendaci√≥n de talla."""
        
        clients = context.get('clients', [])
        products = context.get('products', [])
        
        # Intentar usar contexto de sesi√≥n si no hay informaci√≥n expl√≠cita
        session = self.conversation_manager.get_session(session_id)
        
        if not clients and session and session.active_client:
            clients = [session.active_client]
        
        if not products and session and session.active_product:
            products = [session.active_product]
        
        # Verificar informaci√≥n necesaria
        if not clients:
            return {
                "response": (
                    "Para darte una recomendaci√≥n de talla, necesito saber para qu√© cliente es. "
                    "Por favor, especifica el ID del cliente (ejemplo: C0001, C0002, etc.) "
                    "o usa User seguido del n√∫mero (ejemplo: User1, User2)."
                ),
                "needs_client": True,
                "metadata": {"intent": "size_recommendation", "missing": "client"}
            }
        
        if not products:
            return {
                "response": (
                    "Para recomendarte una talla, necesito saber qu√© producto te interesa. "
                    "Por favor, especifica el ID del producto (ejemplo: P001, P002, etc.)."
                ),
                "needs_product": True,
                "metadata": {"intent": "size_recommendation", "missing": "product"}
            }
        
        # Procesar recomendaci√≥n
        client = clients[0]
        product = products[0]
        
        print(f"‚úÖ Procesando: {client.name} + {product.name}")
        
        # Actualizar contexto de sesi√≥n
        self.conversation_manager.set_active_client(session_id, client)
        self.conversation_manager.set_active_product(session_id, product)
        
        try:
            # Generar recomendaci√≥n t√©cnica
            recommendation = self.recommendation_engine.recommend_size(client, product)
            print(f"üìè Recomendaci√≥n: {recommendation.recommended_size} (conf: {recommendation.confidence:.1%})")
            
            # Generar respuesta con LLM
            conversation_history = self.conversation_manager.get_conversation_history(
                session_id, format_for_llm=True
            )
            
            response = self.llm_service.generate_recommendation_response(
                user_query=message,
                client=client,
                product=product,
                recommendation=recommendation,
                conversation_history=conversation_history
            )
            
            return {
                "response": response,
                "recommendation": {
                    "size": recommendation.recommended_size,
                    "confidence": recommendation.confidence,
                    "alternatives": recommendation.alternative_sizes
                },
                "client": {
                    "id": client.client_id,
                    "name": client.name
                },
                "product": {
                    "id": product.product_id,
                    "name": product.name
                },
                "metadata": {
                    "intent": "size_recommendation",
                    "success": True
                }
            }
            
        except Exception as e:
            print(f"‚ùå Error en recomendaci√≥n: {e}")
            return {
                "response": (
                    f"Encontr√© al cliente {client.name} y el producto {product.name}, "
                    f"pero hubo un error generando la recomendaci√≥n. "
                    f"Por favor, int√©ntalo de nuevo."
                ),
                "error": True,
                "error_details": str(e)
            }
    
    def _handle_product_search(
        self, 
        message: str, 
        session_id: str, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Maneja b√∫squedas de productos."""
        
        products = context.get('products', [])
        
        if not products:
            # Intentar b√∫squeda m√°s amplia
            search_terms = " ".join(context.get('keywords', []))
            if search_terms:
                products = self.data_loader.search_products(search_terms, limit=5)
        
        if not products:
            return {
                "response": (
                    "No encontr√© productos que coincidan con tu b√∫squeda. "
                    "Puedes buscar por ID (ejemplo: P001), material (algod√≥n, lana) "
                    "o tipo de ajuste (slim, regular). "
                    "¬øPodr√≠as ser m√°s espec√≠fico?"
                ),
                "products_found": 0,
                "metadata": {"intent": "product_search", "success": False}
            }
        
        # Generar respuesta
        response = self.llm_service.generate_product_search_response(message, products)
        
        return {
            "response": response,
            "products": [
                {
                    "id": p.product_id,
                    "name": p.name,
                    "fit": p.fit,
                    "fabric": p.fabric
                }
                for p in products[:5]
            ],
            "products_found": len(products),
            "metadata": {
                "intent": "product_search",
                "success": True
            }
        }
    
    def _handle_help_request(self) -> Dict[str, Any]:
        """Maneja solicitudes de ayuda."""
        
        help_response = (
            "¬°Estoy aqu√≠ para ayudarte! ü§ó\n\n"
            "**¬øQu√© puedo hacer por ti?**\n\n"
            "üìè **Recomendaciones de talla:**\n"
            "‚Ä¢ \"¬øQu√© talla del producto P001 para el cliente C0001?\"\n"
            "‚Ä¢ \"Talla para User5 del producto P025\"\n\n"
            "üîç **Buscar productos:**\n"
            "‚Ä¢ \"Busca productos de lana\"\n"
            "‚Ä¢ \"Productos con ajuste slim\"\n\n"
        )
        
        if self.visual_service and self.visual_service.is_available():
            help_response += (
                "üñºÔ∏è **Visualizaciones:**\n"
                "‚Ä¢ \"Muestra P001 en azul para C0001\"\n"
                "‚Ä¢ \"Ver imagen de User2 con P025\"\n\n"
                "üé® **Colores disponibles:**\n"
                "azul, rojo, verde, negro, blanco, gris, rosa, amarillo, morado, naranja\n\n"
            )
        
        help_response += (
            "**Formato de IDs:**\n"
            "‚Ä¢ Clientes: C0001, C0002, etc. (o User1, User2, etc.)\n"
            "‚Ä¢ Productos: P001, P002, etc."
        )
        
        return {
            "response": help_response,
            "metadata": {
                "intent": "help",
                "success": True
            }
        }
    
    def _handle_general_query(self, message: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Maneja consultas generales."""
        
        # Construir contexto para el LLM
        context_str = ""
        if context.get('clients'):
            context_str += f"Clientes mencionados: {[c.name for c in context['clients']]}\n"
        if context.get('products'):
            context_str += f"Productos mencionados: {[p.name for p in context['products']]}\n"
        
        response = self.llm_service.generate_general_response(message, context_str)
        
        return {
            "response": response,
            "metadata": {
                "intent": "general",
                "success": True
            }
        }
    
    def _generate_visual_content(self, message: str, response_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Genera contenido visual si se solicita."""
        try:
            # Obtener objetos completos
            client = self.data_loader.get_client(response_data['client']['id'])
            product = self.data_loader.get_product(response_data['product']['id'])
            
            if not client or not product:
                return None
            
            # Extraer color del mensaje
            color = self._extract_color_from_message(message)
            
            # Generar imagen
            visual_result = self.visual_service.generate_avatar_image(
                client=client,
                product=product,
                size=response_data['recommendation']['size'],
                color=color
            )
            
            return visual_result if visual_result.get('success') else visual_result
            
        except Exception as e:
            print(f"‚ùå Error generando contenido visual: {e}")
            return {"success": False, "error": str(e)}
    
    def _extract_color_from_message(self, message: str) -> str:
        """Extrae el color mencionado en el mensaje."""
        colors = ['azul', 'rojo', 'verde', 'negro', 'blanco', 'gris', 'rosa', 'amarillo', 'morado', 'naranja']
        
        message_lower = message.lower()
        for color in colors:
            if color in message_lower:
                return color
        
        return 'azul'  # Color por defecto
    
    # M√©todos de utilidad
    def get_session_info(self, session_id: str) -> Dict[str, Any]:
        """Obtiene informaci√≥n de la sesi√≥n actual."""
        base_info = self.conversation_manager.get_session_summary(session_id)
        base_info['visual_enabled'] = self.visual_service and self.visual_service.is_available()
        base_info['llm_type'] = 'openai' if self.llm_service.use_openai else 'local'
        return base_info
    
    def clear_session(self, session_id: str) -> None:
        """Limpia una sesi√≥n espec√≠fica."""
        self.conversation_manager.clear_session(session_id)
    
    def get_available_clients(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Obtiene lista de clientes disponibles."""
        clients = self.data_loader.get_all_clients()[:limit]
        return [
            {
                "id": c.client_id,
                "name": c.name,
                "preferred_fit": c.preferred_fit,
                "height_cm": c.height_cm
            }
            for c in clients
        ]
    
    def get_available_products(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Obtiene lista de productos disponibles."""
        products = self.data_loader.get_all_products()[:limit]
        return [
            {
                "id": p.product_id,
                "name": p.name,
                "fit": p.fit,
                "fabric": p.fabric,
                "available_sizes": p.available_sizes
            }
            for p in products
        ]
    
    def test_basic_functionality(self) -> bool:
        """Prueba la funcionalidad b√°sica del chatbot."""
        try:
            session_id = self.start_conversation()
            response = self.process_message("¬øQu√© talla del producto P001 para el cliente C0001?", session_id)
            return not response.get('error', False)
        except Exception as e:
            print(f"‚ùå Error en prueba b√°sica: {e}")
            return False